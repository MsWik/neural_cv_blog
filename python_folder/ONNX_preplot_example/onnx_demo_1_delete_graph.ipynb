{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9f51a9",
   "metadata": {},
   "source": [
    "> В данном примере мы удялем из модели backbone_fpn_head_x_.onnx ноду с именем Conv_1328. Для того что бы выполнить это, нам нужно соеденить вход слоя с его выходом, после чего вызвать для удаляемого слоя метод clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"backbone_fpn_head_x_.onnx\")\n",
    "graph = gs.import_onnx(model)\n",
    "fake_node = [node for node in graph.nodes if node.name == \"Conv_1328\"][0]\n",
    "\n",
    "# Get the input node of the fake node\n",
    "# Node provides i() and o() functions that can optionally be provided an index (default is 0)\n",
    "# These serve as convenience functions for the alternative, which would be to fetch the input/output\n",
    "# tensor first, then fetch the input/output node of the tensor.\n",
    "# For example, node.i() is equivalent to node.inputs[0].inputs[0]\n",
    "inp_node = fake_node.i()\n",
    "\n",
    "# Reconnect the input node to the output tensors of the fake node, so that the first identity\n",
    "# node in the example graph now skips over the fake node.\n",
    "inp_node.outputs = fake_node.outputs\n",
    "fake_node.outputs.clear()\n",
    "\n",
    "# Remove the fake node from the graph completely\n",
    "graph.cleanup()\n",
    "onnx.save(gs.export_onnx(graph), \"removed.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a1e0c",
   "metadata": {},
   "source": [
    "> В данном примере мы объединяем выходы модели 2 с входом модели 1. Так как у нас есть слои с одинаковыми названиями мы переменовываем все слои из модели 2. Выходы и входы которые не указаны в io_map остаются свободными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper, checker\n",
    "\n",
    "model1 = onnx.load('backbone_fpn_head_x_.onnx')\n",
    "\n",
    "model2 = onnx.load('backbone_fpn_z.onnx')\n",
    "checker.check_model(model1)\n",
    "checker.check_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тут мы добовляем префикс в названии модели (т.е m1/ будет добавлено возле каждого имени слоя, иначе если будут слои с одинаковыми именами будет конфликт)\n",
    "new_model_2 = onnx.compose.add_prefix(model2, prefix='m1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11587efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onnx.save(new_model_2, 'new_model_2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = onnx.compose.merge_models(\n",
    "    new_model_2,model1,\n",
    "    io_map=[('m1_feat_z', 'kernel')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(combined_model, 'combined_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904518f",
   "metadata": {},
   "source": [
    "> В данном примере мы показываем как вывести размеры входа и выхода конкретного слоя. Нам это может понадобится для того, что бы создать замену данному слою, если мы захотим его заменить на другой слой (другой слой должен уметь работать с указанными размерностями или иметь перед собоы reshape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ae4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"backbone_fpn_head_x_.onnx\")\n",
    "graph = gs.import_onnx(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c41672bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = graph.tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57472c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327\n"
     ]
    }
   ],
   "source": [
    "for index, node in enumerate(graph.nodes):\n",
    "        if node.name == \"Reshape_1327\":\n",
    "            print(index)\n",
    "            gemm_node = graph.nodes[1327]\n",
    "            np_w = gemm_node.inputs[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d7e1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192,   1,   5,   5], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3201d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326\n"
     ]
    }
   ],
   "source": [
    "for index, node in enumerate(graph.nodes):\n",
    "        if node.name == \"Reshape_1326\":\n",
    "            print(index)\n",
    "            gemm_node = graph.nodes[1326]\n",
    "            np_w = gemm_node.inputs[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7579eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 192,  20,  20], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd47b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329\n"
     ]
    }
   ],
   "source": [
    "for index, node in enumerate(graph.nodes):\n",
    "        if node.name == \"Reshape_1329\":\n",
    "            print(index)\n",
    "            gemm_node = graph.nodes[1329]\n",
    "            np_w = gemm_node.inputs[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e659f278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 192,  20,  20], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f35ff",
   "metadata": {},
   "source": [
    "> В данном примере мы показываем как удалить ноду Conv_1328, встаить в место нее другую ноду после чего записать другую ноду в граф. Для того, что бы записать другую ноду мы должны знать где вход и выход новой ноды. Далее, так как оичстка не удаляет вход, мы удаляем вход сами вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93d0a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328\n"
     ]
    }
   ],
   "source": [
    "import onnx_graphsurgeon as gs\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"backbone_fpn_head_x_.onnx\")\n",
    "graph = gs.import_onnx(model)\n",
    "\n",
    "for index, node in enumerate(graph.nodes):\n",
    "        \n",
    "        if node.name == \"Conv_1328\":\n",
    "            print(index)\n",
    "            gemm_node = graph.nodes[index]\n",
    "            #np_w = gemm_node.inputs[1].values\n",
    "            np_w = np.random.rand(192,   1,   5,   5)\n",
    "            conv_w = gs.Constant(name='W', values=np_w)\n",
    "            #conv_out_0 = gs.Variable(name='conv_new_0', dtype=np.float32, shape=(192,   1,   5,   5))\n",
    "            conv_node_0 = gs.Node(op='Conv', name= 'Conv_1000', inputs=[node.inputs[0], conv_w], outputs=[node.outputs[0]],\n",
    "                                 attrs={\n",
    "                    'dilations':[1,1],\n",
    "                    'group':192, \n",
    "                    'kernel_shape':[5,5],\n",
    "                    'pads':[2,2,2,2],\n",
    "                    'strides':[1,1],\n",
    "                    \n",
    "                    }\n",
    "                                 \n",
    "                                 \n",
    "                                 )\n",
    "            graph.nodes.append(conv_node_0)\n",
    "            node.outputs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf5f9666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable (img_x): (shape=[1, 3, 320, 320], dtype=float32),\n",
       " Variable (kernel): (shape=[1, 192, 5, 5], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0de2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable (kernel): (shape=[1, 192, 5, 5], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.inputs.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "777ef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.cleanup()\n",
    "modified_model = gs.export_onnx(graph)\n",
    "#onnx.checker.check_model(modified_model)\n",
    "onnx.save(gs.export_onnx(graph), \"removed.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820e6a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "Nodes in a graph must be topologically sorted, however input 'onnx::Reshape_2916' of node: \nname: Reshape_1329 OpType: Reshape\n is not output of any previous nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BIASPA~1\\AppData\\Local\\Temp/ipykernel_23172/4224503246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# convert model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_simp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimplify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Simplified ONNX model could not be validated\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\onnxsim\\onnx_simplifier.py\u001b[0m in \u001b[0;36msimplify\u001b[1;34m(model, check_n, perform_optimization, skip_fuse_bn, input_shapes, skipped_optimizers, skip_shape_inference, input_data, dynamic_input_shape, custom_lib)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelProto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m     \u001b[0mmodel_ori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\onnx\\checker.py\u001b[0m in \u001b[0;36mcheck_model\u001b[1;34m(model, full_check)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotobuf_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mMAXIMUM_PROTOBUF\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This protobuf of onnx model is too large (>2GB). Call check_model with model path instead.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotobuf_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_inference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: Nodes in a graph must be topologically sorted, however input 'onnx::Reshape_2916' of node: \nname: Reshape_1329 OpType: Reshape\n is not output of any previous nodes."
     ]
    }
   ],
   "source": [
    "from onnxsim import simplify\n",
    "\n",
    "# load your predefined ONNX model\n",
    "model = onnx.load(\"removed.onnx\")\n",
    "\n",
    "# convert model\n",
    "model_simp, check = simplify(model)\n",
    "\n",
    "assert check, \"Simplified ONNX model could not be validated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2319d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
