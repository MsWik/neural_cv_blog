{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75daeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session OK\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess_options = rt.SessionOptions()\n",
    "\n",
    "# Уровень оптимизиции (по факту результат заметен не был)\n",
    "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "# To enable model serialization after graph optimization set this\n",
    "sess_options.optimized_model_filepath = \"dasiamrpn_model_271.onnx\"\n",
    "\n",
    "session = rt.InferenceSession(\"dasiamrpn_model_271.onnx\", sess_options,providers=[\"CUDAExecutionProvider\"])\n",
    "print(\"session OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe6591a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/08/2022-14:35:10] [TRT] [I] [MemUsageChange] Init CUDA: CPU +341, GPU +0, now: CPU 23101, GPU 1184 (MiB)\n",
      "[04/08/2022-14:35:10] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 23175 MiB, GPU 1184 MiB\n",
      "[04/08/2022-14:35:11] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 23318 MiB, GPU 1220 MiB\n",
      "[04/08/2022-14:35:11] [TRT] [W] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[04/08/2022-14:35:11] [TRT] [I] No importer registered for op: FusedConv. Attempting to import as plugin.\n",
      "[04/08/2022-14:35:11] [TRT] [I] Searching for plugin: FusedConv, plugin_version: 1, plugin_namespace: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:EngineBuilder:Failed to load ONNX file: C:\\Users\\biaspaltsau_aa\\python_folder\\debag_nn\\backbone_fpn_head_x.onnx\n",
      "ERROR:EngineBuilder:In node 1 (importFallbackPluginImporter): UNSUPPORTED_NODE: Assertion failed: creator && \"Plugin not found, are the plugin name, version, and namespace correct?\"\n"
     ]
    }
   ],
   "source": [
    "!python build_engine.py     --onnx dasiamrpn_model_271_.onnx     --engine dasiamrpn_model32_r_271.trt     --precision fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46da232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from onnx2torch import convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46775ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch\n",
    "from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35b08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to ONNX model\n",
    "onnx_model_path = 'dasiamrpn_model.onnx'\n",
    "# You can pass the path to the onnx model to convert it or...\n",
    "torch_model_1 = convert(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90089c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (Conv_0): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))\n",
       "  (BatchNormalization_0): BatchNorm2d(96, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (MaxPool_0): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Relu_0): ReLU()\n",
       "  (Conv_1): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (BatchNormalization_1): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (MaxPool_1): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Relu_1): ReLU()\n",
       "  (Conv_2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_2): BatchNorm2d(384, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Relu_2): ReLU()\n",
       "  (Conv_3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_3): BatchNorm2d(384, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Relu_3): ReLU()\n",
       "  (Conv_4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_4): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (Conv_6): Conv2d(256, 20, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  (Conv_7): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (Conv_9): Conv2d(256, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model_1.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d40592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biaspaltsau_aa\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\utils.py:1327: UserWarning: Provided key input for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.1280,  0.1410,  0.1360,  ...,  0.1348,  0.1334,  0.1339],\n",
       "           [ 0.1375,  0.1462,  0.1412,  ...,  0.1261,  0.1214,  0.1230],\n",
       "           [ 0.1444,  0.1459,  0.1446,  ...,  0.1274,  0.1213,  0.1275],\n",
       "           ...,\n",
       "           [ 0.1360,  0.1399,  0.1349,  ...,  0.1416,  0.1330,  0.1445],\n",
       "           [ 0.1383,  0.1432,  0.1383,  ...,  0.1475,  0.1408,  0.1503],\n",
       "           [ 0.1384,  0.1421,  0.1384,  ...,  0.1409,  0.1386,  0.1438]],\n",
       " \n",
       "          [[ 0.1376,  0.1513,  0.1473,  ...,  0.1455,  0.1458,  0.1455],\n",
       "           [ 0.1457,  0.1567,  0.1536,  ...,  0.1370,  0.1342,  0.1360],\n",
       "           [ 0.1481,  0.1540,  0.1546,  ...,  0.1386,  0.1350,  0.1396],\n",
       "           ...,\n",
       "           [ 0.1495,  0.1536,  0.1441,  ...,  0.1523,  0.1452,  0.1542],\n",
       "           [ 0.1492,  0.1540,  0.1468,  ...,  0.1595,  0.1548,  0.1592],\n",
       "           [ 0.1506,  0.1546,  0.1506,  ...,  0.1536,  0.1524,  0.1511]],\n",
       " \n",
       "          [[ 0.0415,  0.0540,  0.0577,  ...,  0.0498,  0.0556,  0.0631],\n",
       "           [ 0.0476,  0.0575,  0.0603,  ...,  0.0441,  0.0462,  0.0561],\n",
       "           [ 0.0447,  0.0537,  0.0555,  ...,  0.0417,  0.0445,  0.0505],\n",
       "           ...,\n",
       "           [ 0.0560,  0.0606,  0.0481,  ...,  0.0559,  0.0528,  0.0520],\n",
       "           [ 0.0505,  0.0515,  0.0414,  ...,  0.0555,  0.0600,  0.0554],\n",
       "           [ 0.0498,  0.0521,  0.0477,  ...,  0.0538,  0.0592,  0.0487]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1907,  0.1970,  0.1825,  ...,  0.1628,  0.1780,  0.1698],\n",
       "           [ 0.2022,  0.2011,  0.1820,  ...,  0.1525,  0.1694,  0.1699],\n",
       "           [ 0.1881,  0.1870,  0.1667,  ...,  0.1534,  0.1680,  0.1688],\n",
       "           ...,\n",
       "           [ 0.1752,  0.1642,  0.1739,  ...,  0.1784,  0.1721,  0.1679],\n",
       "           [ 0.1679,  0.1701,  0.1773,  ...,  0.1926,  0.1853,  0.1763],\n",
       "           [ 0.1644,  0.1834,  0.1896,  ...,  0.1888,  0.1822,  0.1688]],\n",
       " \n",
       "          [[ 0.1807,  0.1986,  0.2040,  ...,  0.1744,  0.1729,  0.1740],\n",
       "           [ 0.1773,  0.1929,  0.1919,  ...,  0.1528,  0.1512,  0.1630],\n",
       "           [ 0.1601,  0.1733,  0.1737,  ...,  0.1487,  0.1499,  0.1656],\n",
       "           ...,\n",
       "           [ 0.1568,  0.1716,  0.1622,  ...,  0.1804,  0.1672,  0.1587],\n",
       "           [ 0.1605,  0.1695,  0.1611,  ...,  0.1752,  0.1666,  0.1557],\n",
       "           [ 0.1731,  0.1843,  0.1761,  ...,  0.1773,  0.1721,  0.1517]],\n",
       " \n",
       "          [[-0.0988, -0.0848, -0.0739,  ..., -0.0907, -0.0956, -0.1012],\n",
       "           [-0.0939, -0.0818, -0.0747,  ..., -0.1060, -0.1118, -0.1109],\n",
       "           [-0.1024, -0.0915, -0.0832,  ..., -0.1156, -0.1187, -0.1106],\n",
       "           ...,\n",
       "           [-0.1131, -0.1028, -0.1145,  ..., -0.0947, -0.1124, -0.1101],\n",
       "           [-0.1051, -0.1083, -0.1204,  ..., -0.0978, -0.1143, -0.1164],\n",
       "           [-0.0897, -0.0945, -0.1051,  ..., -0.0978, -0.1085, -0.1186]]]],\n",
       "        device='cuda:0', grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[[ 3.2094,  3.2891,  3.0897,  ...,  3.1236,  3.3034,  3.3804],\n",
       "           [ 3.2420,  3.2908,  3.0775,  ...,  3.0722,  3.2452,  3.3066],\n",
       "           [ 3.2274,  3.2361,  3.0416,  ...,  3.0057,  3.1025,  3.1523],\n",
       "           ...,\n",
       "           [ 2.8631,  2.9938,  3.0374,  ...,  3.0430,  3.0729,  2.9996],\n",
       "           [ 2.8755,  3.0383,  3.0164,  ...,  3.0545,  3.0834,  2.9876],\n",
       "           [ 2.8841,  3.0240,  2.9619,  ...,  3.1433,  3.1087,  2.9334]],\n",
       " \n",
       "          [[ 0.5165,  0.3998,  0.4526,  ...,  0.4118,  0.4241,  0.4687],\n",
       "           [ 0.5007,  0.4691,  0.5412,  ...,  0.3259,  0.3549,  0.3997],\n",
       "           [ 0.5676,  0.6341,  0.6689,  ...,  0.1527,  0.1599,  0.2125],\n",
       "           ...,\n",
       "           [ 0.1170,  0.1482,  0.2280,  ...,  0.2967,  0.5996,  0.6035],\n",
       "           [ 0.1518,  0.1641,  0.2999,  ...,  0.2765,  0.5215,  0.5602],\n",
       "           [ 0.2597,  0.2110,  0.2604,  ...,  0.3648,  0.4922,  0.4700]],\n",
       " \n",
       "          [[ 2.4987,  2.4855,  2.5925,  ...,  2.5783,  2.6163,  2.6026],\n",
       "           [ 2.5229,  2.5104,  2.5860,  ...,  2.5825,  2.5990,  2.5524],\n",
       "           [ 2.5494,  2.5647,  2.6269,  ...,  2.5638,  2.5554,  2.5499],\n",
       "           ...,\n",
       "           [ 2.4803,  2.6966,  2.7451,  ...,  2.5748,  2.6208,  2.5032],\n",
       "           [ 2.5231,  2.7971,  2.7489,  ...,  2.6616,  2.6901,  2.5483],\n",
       "           [ 2.4304,  2.7279,  2.6771,  ...,  2.6900,  2.7239,  2.5461]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.8357,  4.8399,  4.8976,  ...,  4.8883,  4.7738,  4.9059],\n",
       "           [ 4.8521,  4.8663,  4.8049,  ...,  4.8125,  4.8312,  5.0240],\n",
       "           [ 4.8833,  4.9212,  4.8029,  ...,  4.7436,  4.9318,  5.2017],\n",
       "           ...,\n",
       "           [ 5.0953,  5.1150,  5.2744,  ...,  4.8730,  4.9610,  4.9754],\n",
       "           [ 4.9900,  4.9753,  5.2603,  ...,  4.9312,  5.0376,  5.1338],\n",
       "           [ 4.9345,  4.9059,  5.2050,  ...,  5.0646,  5.0966,  5.1991]],\n",
       " \n",
       "          [[-2.9209, -2.7190, -2.4499,  ..., -2.5965, -2.4687, -2.4764],\n",
       "           [-2.6768, -2.5244, -2.3838,  ..., -2.5020, -2.3876, -2.4315],\n",
       "           [-2.5288, -2.4765, -2.5212,  ..., -2.4964, -2.4465, -2.4870],\n",
       "           ...,\n",
       "           [-2.6671, -2.4606, -2.4879,  ..., -2.7222, -2.9687, -2.6743],\n",
       "           [-2.7769, -2.5806, -2.6578,  ..., -2.7167, -3.0148, -2.8127],\n",
       "           [-2.7418, -2.6707, -2.8185,  ..., -2.7368, -2.9577, -2.8384]],\n",
       " \n",
       "          [[ 1.6236,  1.5467,  1.6026,  ...,  1.6015,  1.5073,  1.4224],\n",
       "           [ 1.7514,  1.6017,  1.5740,  ...,  1.6391,  1.4675,  1.3242],\n",
       "           [ 1.6733,  1.5085,  1.4423,  ...,  1.5921,  1.4298,  1.3091],\n",
       "           ...,\n",
       "           [ 1.7621,  1.5683,  1.5905,  ...,  1.6317,  1.5980,  1.5296],\n",
       "           [ 1.6470,  1.5145,  1.5391,  ...,  1.6360,  1.5344,  1.4681],\n",
       "           [ 1.5589,  1.4755,  1.4815,  ...,  1.6229,  1.4928,  1.4817]]]],\n",
       "        device='cuda:0', grad_fn=<ConvolutionBackward0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3,271, 271).cuda()\n",
    "\n",
    "torch.onnx._export(\n",
    "        torch_model_1,\n",
    "        dummy_input,\n",
    "        \"dasiamrpn_model_271_.onnx\",\n",
    "        input_names = ['input.1'],   # the model's input names\n",
    "                  output_names = ['output0','output1'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output0' : {0 : 'batch_size'},\n",
    "                               'output1' : {0 : 'batch_size'},\n",
    "                         },\n",
    "        opset_version=9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6cd62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to ONNX model\n",
    "onnx_model_path = 'dasiamrpn_model_271_.onnx'\n",
    "# You can pass the path to the onnx model to convert it or...\n",
    "torch_model_1 = convert(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b880a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.ones(1, 3, 271, 271).cuda()\n",
    "# model_trt = torch2trt(\n",
    "#         torch_model_1.cuda().eval(),\n",
    "#         [x],\n",
    "#         fp16_mode=False,\n",
    "#         log_level=trt.Logger.INFO,\n",
    "#         max_workspace_size=(1 << 32),\n",
    "#         max_batch_size=1,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "343a2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"AlexNet_trt16_287.engine\", \"wb\") as f:\n",
    "#         f.write(model_trt.engine.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a86c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bcf12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session OK\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess_options = rt.SessionOptions()\n",
    "\n",
    "# Уровень оптимизиции (по факту результат заметен не был)\n",
    "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "# To enable model serialization after graph optimization set this\n",
    "sess_options.optimized_model_filepath = \"dasiamrpn_model.onnx\"\n",
    "\n",
    "session = rt.InferenceSession(\"dasiamrpn_model.onnx\", sess_options,providers=[\"CUDAExecutionProvider\"])\n",
    "print(\"session OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e405101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "# def load_engine(trt_runtime, engine_path):\n",
    "#     with open(engine_path, 'rb') as f:\n",
    "#         engine_data = f.read()\n",
    "#     engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "#     return engine\n",
    "\n",
    "def load_engine(trt_runtime, engine_path):\n",
    "    trt.init_libnvinfer_plugins(None, \"\")             ### Try to add here\n",
    "    with open(engine_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "trt_engine_path = \"dasiamrpn_model32_r_271.trt\"\n",
    "trt_engine = load_engine(trt_runtime, trt_engine_path)\n",
    "\n",
    "if trt_engine is not None:\n",
    "    print(\"Success\")                                        \n",
    "else:\n",
    "    print(\"Failed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f7aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(context, input_img, output_size, batch_size):\n",
    "    # Load engine\n",
    "    # engine = context.get_engine()\n",
    "    # assert(engine.get_nb_bindings() == 2)\n",
    "    # Convert input data to float32\n",
    "    input_img = input_img.astype(np.float32)\n",
    "    # Create host buffer to receive data\n",
    "    output_0 = np.empty(output_size[0], dtype = np.float32)\n",
    "    output_1 = np.empty(output_size[1], dtype = np.float32)\n",
    "\n",
    "    # Allocate device memory\n",
    "    d_input = cuda.mem_alloc(batch_size * input_img.size * input_img.dtype.itemsize)\n",
    "    d_output_0 = cuda.mem_alloc(batch_size * output_0.size * output_0.dtype.itemsize)\n",
    "    d_output_1 = cuda.mem_alloc(batch_size * output_1.size * output_1.dtype.itemsize)\n",
    "\n",
    "\n",
    "    bindings = [int(d_input), int(d_output_0), int(d_output_1) ]\n",
    "    stream = cuda.Stream()\n",
    "    # Transfer input data to device\n",
    "    #print(type(input_img))\n",
    "    cuda.memcpy_htod_async(d_input, input_img, stream)\n",
    "    # Execute model\n",
    "    context.execute_async(batch_size, bindings, stream.handle, None)\n",
    "    # Transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output_0, d_output_0, stream)\n",
    "    cuda.memcpy_dtoh_async(output_1, d_output_1, stream)\n",
    "\n",
    "    # Synchronize threads\n",
    "    stream.synchronize()\n",
    "    # Return predictions\n",
    "    return output_0, output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db924fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = trt_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349f2cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(0,1000):\n",
    "    #temp = np.random.rand(1, 3, 287, 287)\n",
    "    temp = np.random.rand(1, 3, 271, 271).astype(np.float32)\n",
    "    #trt_outputs = infer(context, temp, (1, 256, 26, 26), 1)\n",
    "    trt_outputs = infer(context, temp, ((20, 19, 19),(10, 19, 19)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8c74e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89c5f5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (Conv_0): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))\n",
       "  (BatchNormalization_0): BatchNorm2d(96, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (MaxPool_0): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Relu_0): ReLU()\n",
       "  (Conv_1): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (BatchNormalization_1): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (MaxPool_1): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[0, 0], dilation=1, ceil_mode=False)\n",
       "  (Relu_1): ReLU()\n",
       "  (Conv_2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_2): BatchNorm2d(384, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Relu_2): ReLU()\n",
       "  (Conv_3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_3): BatchNorm2d(384, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Relu_3): ReLU()\n",
       "  (Conv_4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (BatchNormalization_4): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (Conv_6): Conv2d(256, 20, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  (Conv_7): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (Conv_8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (Conv_9): Conv2d(256, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model_1.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397428d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "delta_time_prosent=0\n",
    "counter=0\n",
    "fps_counter_onnx=0\n",
    "fps_counter_torch=0\n",
    "fps_counter_trt=0\n",
    "while True:\n",
    "        ret, origin_img = cap.read()\n",
    "        \n",
    "\n",
    "\n",
    "        start_time = time.time() # start time of the loop\n",
    "        #################################################\n",
    "\n",
    "        input_shape = (271,271)\n",
    "        resized = cv2.resize(origin_img, input_shape, interpolation = cv2.INTER_AREA)\n",
    "        resized = np.array(resized,dtype=np.float32)\n",
    "        resized=resized.reshape(3,271,271)\n",
    "        ort_inputs = {session.get_inputs()[0].name: resized[None, :, :, :]}\n",
    "        \n",
    "        timer_trt = cv2.getTickCount()\n",
    "        trt_outputs = infer(context, resized[None, :, :, :], ((1,20,19,19),(1,10,19,19)), 1)\n",
    "        fps_trt = cv2.getTickFrequency() / (cv2.getTickCount() - timer_trt);\n",
    "        fps_counter_trt+=fps_trt\n",
    "        \n",
    "        \n",
    "        \n",
    "        timer = cv2.getTickCount()\n",
    "        output_onnx = session.run(None, ort_inputs)\n",
    "        #print(output_onnx[0].shape)\n",
    "        fps_onnx = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    "        \n",
    "        cv2.putText(origin_img, str(fps_onnx), (10,100), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255))\n",
    "        \n",
    "        \n",
    "        timer_torch = cv2.getTickCount()\n",
    "        x_data = torch.tensor(resized[None, :, :, :]).cuda()\n",
    "        #torch_data = torch_model_1(x_data).cpu().detach().numpy()\n",
    "        #print(torch_data.shape)\n",
    "        fps_torch = cv2.getTickFrequency() / (cv2.getTickCount() - timer_torch);\n",
    "        #print(MSE(torch_data,output_onnx[0]))\n",
    "        \n",
    "        fps_counter_onnx+=fps_onnx\n",
    "        fps_counter_torch+=fps_torch\n",
    "        \n",
    "        \n",
    "#         timer_trt = cv2.getTickCount()\n",
    "#         trt_outputs = infer(context, resized[None, :, :, :], (1, 256, 26, 26), 1)\n",
    "#         fps_trt = cv2.getTickFrequency() / (cv2.getTickCount() - timer_trt);\n",
    "#         fps_counter_trt+=fps_trt\n",
    "        #print(MSE(torch_data,output_onnx[0]))\n",
    "        \n",
    "        \n",
    "        counter+=1\n",
    "        if counter%100==0:\n",
    "            print(\"fps_onnx\",fps_counter_onnx/100)\n",
    "            print(\"fps_torch\",fps_counter_torch/100)\n",
    "            print(\"fps_trt\",fps_counter_trt/100)\n",
    "            print(\"MSE trt_outputs - output_onnx\",MSE(trt_outputs,output_onnx[0]))\n",
    "            #print(\"MSE torch_data - trt_outputs\",MSE(torch_data,trt_outputs))\n",
    "            fps_counter_onnx=0\n",
    "            fps_counter_torch=0\n",
    "            fps_counter_trt=0\n",
    "            counte=0\n",
    "        \n",
    "\n",
    "        cv2.imshow('Input', origin_img)\n",
    "\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c0fb1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af1b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "\n",
    "# load your predefined ONNX model\n",
    "model = onnx.load(\"dasiamrpn_model.onnx\")\n",
    "\n",
    "# convert model\n",
    "model_simp, check = simplify(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f87662",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(model_simp, \"dasiamrpn_model_271_n.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06434da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
